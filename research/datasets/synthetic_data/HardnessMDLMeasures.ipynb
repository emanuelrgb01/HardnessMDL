{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "path_to_research = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "if path_to_research not in sys.path:\n",
    "    sys.path.insert(0, path_to_research)\n",
    "\n",
    "print(f\"sys.path: {path_to_research}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bfc916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import hardnessmdl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('two_classes/test1.csv')\n",
    "df2 = pd.read_csv('two_classes/test2.csv')\n",
    "df3 = pd.read_csv('two_classes/test3.csv')\n",
    "df4 = pd.read_csv('two_classes/test4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dceb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5), sharey=True)\n",
    "fig.suptitle('Scatter Plots of DataFrames')\n",
    "\n",
    "sns.scatterplot(ax=axes[0], data=df1, x='X', y='Y', hue='class')\n",
    "axes[0].set_title('DataFrame 1')\n",
    "\n",
    "sns.scatterplot(ax=axes[1], data=df2, x='X', y='Y', hue='class')\n",
    "axes[1].set_title('DataFrame 2')\n",
    "\n",
    "sns.scatterplot(ax=axes[2], data=df3, x='X', y='Y', hue='class')\n",
    "axes[2].set_title('DataFrame 3')\n",
    "\n",
    "sns.scatterplot(ax=axes[3], data=df4, x='X', y='Y', hue='class')\n",
    "axes[3].set_title('DataFrame 4')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9fdea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_single(\n",
    "    test_index: int,\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    label_col: str,\n",
    "    class_map: Dict[str, int],\n",
    "    n_classes: int,\n",
    "    n_dims: int,\n",
    "    kwargs: Dict[str, Any],\n",
    "):\n",
    "    \"\"\"Auxiliary function\"\"\"\n",
    "    test_df = df.loc[[test_index]]\n",
    "    train_df = df.drop(index=test_index)\n",
    "\n",
    "    model = hardnessmdl.HardnessMDL(n_classes=n_classes, n_dims=n_dims)\n",
    "\n",
    "    model.set_learning_rate(kwargs.get(\"learning_rate\", 0.01))\n",
    "    model.set_momentum(kwargs.get(\"momentum\", 0.9))\n",
    "    model.set_tau(kwargs.get(\"tau\", 0))\n",
    "    model.set_omega(kwargs.get(\"omega\", 32.0))\n",
    "    model.set_forgetting_factor(kwargs.get(\"forgetting_factor\", 1.0))\n",
    "    model.set_sigma(kwargs.get(\"sigma\", 1.0))\n",
    "\n",
    "    X_train = train_df[feature_cols].to_numpy()\n",
    "    y_train_names = train_df[label_col].to_numpy()\n",
    "\n",
    "    X_test = test_df[feature_cols].to_numpy()\n",
    "    y_test_name = test_df[label_col].to_numpy()[0]\n",
    "    true_label = class_map[y_test_name]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    for j in range(len(X_train_scaled)):\n",
    "        features = X_train_scaled[j]\n",
    "        label = class_map[y_train_names[j]]\n",
    "        model.train(features, label)\n",
    "\n",
    "    hardness_dict = model.hardness(X_test_scaled[0], true_label)\n",
    "\n",
    "    feature_dict = {col: val for col, val in zip(feature_cols, X_test[0])}\n",
    "\n",
    "    return {\n",
    "        \"index\": test_index,\n",
    "        **feature_dict,\n",
    "        **hardness_dict,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_loo_hardness(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    label_col: str,\n",
    "    n_jobs: int = os.cpu_count() // 2,\n",
    "    **kwargs: Dict[str, Any],\n",
    ") -> List[Any]:\n",
    "    \"\"\"\n",
    "    Parallel Leave-One-Out hardness computation using joblib + tqdm.\n",
    "    Computes hardness measures for each sample in a dataframe using\n",
    "    Leave-One-Out cross-validation.\n",
    "\n",
    "    Args:\n",
    "        df: The full dataframe containing all samples.\n",
    "        feature_cols: A list of column names to be used as features.\n",
    "        label_col: The name of the column containing the class label.\n",
    "        **kwargs: Hyperparameters for the GMDL model.\n",
    "\n",
    "    Returns:\n",
    "        A list of hardness measures, one for each sample in the original dataframe.\n",
    "    \"\"\"\n",
    "    class_names = sorted(df[label_col].unique().tolist())\n",
    "    class_map = {name: i for i, name in enumerate(class_names)}\n",
    "    n_classes = len(class_names)\n",
    "    n_dims = len(feature_cols)\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs, batch_size=\"auto\")(\n",
    "        delayed(_compute_single)(\n",
    "            test_index,\n",
    "            df,\n",
    "            feature_cols,\n",
    "            label_col,\n",
    "            class_map,\n",
    "            n_classes,\n",
    "            n_dims,\n",
    "            kwargs,\n",
    "        )\n",
    "        for test_index in df.index\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7960c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_description_lenght_single_instance(\n",
    "    test_index: int,\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    label_col: str,\n",
    "    class_map: Dict[str, int],\n",
    "    n_classes: int,\n",
    "    n_dims: int,\n",
    "    kwargs: Dict[str, Any],\n",
    "):\n",
    "    \"\"\"Auxiliary function\"\"\"\n",
    "    test_df = df.loc[[test_index]]\n",
    "    train_df = df.drop(index=test_index)\n",
    "\n",
    "    model = hardnessmdl.HardnessMDL(n_classes=n_classes, n_dims=n_dims)\n",
    "\n",
    "    model.set_learning_rate(kwargs.get(\"learning_rate\", 0.01))\n",
    "    model.set_momentum(kwargs.get(\"momentum\", 0.9))\n",
    "    model.set_tau(kwargs.get(\"tau\", 0))\n",
    "    model.set_omega(kwargs.get(\"omega\", 32.0))\n",
    "    model.set_forgetting_factor(kwargs.get(\"forgetting_factor\", 1.0))\n",
    "    model.set_sigma(kwargs.get(\"sigma\", 1.0))\n",
    "\n",
    "    X_train = train_df[feature_cols].to_numpy()\n",
    "    y_train_names = train_df[label_col].to_numpy()\n",
    "\n",
    "    X_test = test_df[feature_cols].to_numpy()\n",
    "    y_test_name = test_df[label_col].to_numpy()[0]\n",
    "    true_label = class_map[y_test_name]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    for j in range(len(X_train_scaled)):\n",
    "        features = X_train_scaled[j]\n",
    "        label = class_map[y_train_names[j]]\n",
    "        model.train(features, label)\n",
    "\n",
    "    prediction_dict = model.predict(X_test_scaled[0])\n",
    "\n",
    "    feature_dict = {col: val for col, val in zip(feature_cols, X_test[0])}\n",
    "\n",
    "    return {\n",
    "        \"index\": test_index,\n",
    "        \"true_label\": true_label,\n",
    "        **feature_dict,\n",
    "        **prediction_dict,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_loo_description_lenght(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    label_col: str,\n",
    "    n_jobs: int = os.cpu_count() // 2,\n",
    "    **kwargs: Dict[str, Any],\n",
    ") -> List[Any]:\n",
    "    \"\"\"\n",
    "    Parallel Leave-One-Out Description Lenght computation using joblib + tqdm.\n",
    "    Computes Description Lenght for each sample in a dataframe using\n",
    "    Leave-One-Out cross-validation.\n",
    "\n",
    "    Args:\n",
    "        df: The full dataframe containing all samples.\n",
    "        feature_cols: A list of column names to be used as features.\n",
    "        label_col: The name of the column containing the class label.\n",
    "        **kwargs: Hyperparameters for the GMDL model.\n",
    "\n",
    "    Returns:\n",
    "        A list of Description Lenght, one for each sample in the original dataframe.\n",
    "    \"\"\"\n",
    "    class_names = sorted(df[label_col].unique().tolist())\n",
    "    class_map = {name: i for i, name in enumerate(class_names)}\n",
    "    n_classes = len(class_names)\n",
    "    n_dims = len(feature_cols)\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs, batch_size=\"auto\")(\n",
    "        delayed(_compute_description_lenght_single_instance)(\n",
    "            test_index,\n",
    "            df,\n",
    "            feature_cols,\n",
    "            label_col,\n",
    "            class_map,\n",
    "            n_classes,\n",
    "            n_dims,\n",
    "            kwargs,\n",
    "        )\n",
    "        for test_index in df.index\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fe424",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['X', 'Y']\n",
    "label_column = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a240e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measures1 = compute_loo_hardness(df1, feature_columns, label_column)\n",
    "measures1 = compute_loo_description_lenght(df1, feature_columns, label_column)\n",
    "df1_result = pd.DataFrame(measures1)\n",
    "df1_result.to_csv(\"two_classes/results/test1_description_lenght.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d55226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measures2 = compute_loo_hardness(df2, feature_columns, label_column)\n",
    "measures2 = compute_loo_description_lenght(df2, feature_columns, label_column)\n",
    "df2_result = pd.DataFrame(measures2)\n",
    "df2_result.to_csv(\"two_classes/results/test2_description_lenght.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8955e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measures3 = compute_loo_hardness(df3, feature_columns, label_column)\n",
    "measures3 = compute_loo_description_lenght(df3, feature_columns, label_column)\n",
    "df3_result = pd.DataFrame(measures3)\n",
    "df3_result.to_csv(\"two_classes/results/test3_description_lenght.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5acf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measures4 = compute_loo_hardness(df4, feature_columns, label_column)\n",
    "measures4 = compute_loo_description_lenght(df4, feature_columns, label_column)\n",
    "df4_result = pd.DataFrame(measures4)\n",
    "df4_result.to_csv(\"two_classes/results/test4_description_lenght.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c02a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f4c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df1_result.label - df1_result.true_label).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c432917",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74afbeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df1_result, df2_result, df3_result, df4_result]\n",
    "\n",
    "df_meta_feats_dict = {}\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    df_meta_feats_dict[f'DataFrame {i+1}'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=4, subplot_titles=(\n",
    "    \"DataFrame 1\",\n",
    "    \"DataFrame 2\",\n",
    "    \"DataFrame 3\",\n",
    "    \"DataFrame 4\"\n",
    "))\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    df_name = f'DataFrame {i+1}'\n",
    "    dcp_values = df_meta_feats_dict[df_name]['r_min']\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=df[\"X\"], y=df[\"Y\"], mode='markers',\n",
    "                             marker=dict(color=dcp_values,\n",
    "                                         colorscale='viridis',\n",
    "                                         cmin=0, cmax=1, \n",
    "                                         showscale=True if i == 3 else False, \n",
    "                                         colorbar=dict(title='r_min', x=1.02)),\n",
    "                             name=df_name),\n",
    "                  row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(title_text=\"Scatter Plots of DataFrames 1 to 4\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f41722",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=4, subplot_titles=(\n",
    "    \"DataFrame 1\",\n",
    "    \"DataFrame 2\",\n",
    "    \"DataFrame 3\",\n",
    "    \"DataFrame 4\"\n",
    "))\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    df_name = f'DataFrame {i+1}'\n",
    "    dcp_values = df_meta_feats_dict[df_name]['r_med']\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=df[\"X\"], y=df[\"Y\"], mode='markers',\n",
    "                             marker=dict(color=dcp_values,\n",
    "                                         colorscale='viridis',\n",
    "                                         cmin=0, cmax=1, \n",
    "                                         showscale=True if i == 3 else False, \n",
    "                                         colorbar=dict(title='r_med', x=1.02)),\n",
    "                             name=df_name),\n",
    "                  row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(title_text=\"Scatter Plots of DataFrames 1 to 4\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=4, subplot_titles=(\n",
    "    \"DataFrame 1\",\n",
    "    \"DataFrame 2\",\n",
    "    \"DataFrame 3\",\n",
    "    \"DataFrame 4\"\n",
    "))\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    df_name = f'DataFrame {i+1}'\n",
    "    dcp_values = df_meta_feats_dict[df_name]['relative_position']\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=df[\"X\"], y=df[\"Y\"], mode='markers',\n",
    "                             marker=dict(color=dcp_values,\n",
    "                                         colorscale='viridis',\n",
    "                                         cmin=0, cmax=1, \n",
    "                                         showscale=True if i == 3 else False, \n",
    "                                         colorbar=dict(title='relative_position', x=1.02)),\n",
    "                             name=df_name),\n",
    "                  row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(title_text=\"Scatter Plots of DataFrames 1 to 4\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=4, subplot_titles=(\n",
    "    \"DataFrame 1\",\n",
    "    \"DataFrame 2\",\n",
    "    \"DataFrame 3\",\n",
    "    \"DataFrame 4\"\n",
    "))\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    df_name = f'DataFrame {i+1}'\n",
    "    dcp_values = df_meta_feats_dict[df_name]['pseudo_probability']\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=df[\"X\"], y=df[\"Y\"], mode='markers',\n",
    "                             marker=dict(color=dcp_values,\n",
    "                                         colorscale='viridis',\n",
    "                                         cmin=0, cmax=1, \n",
    "                                         showscale=True if i == 3 else False, \n",
    "                                         colorbar=dict(title='pseudo_probability', x=1.02)),\n",
    "                             name=df_name),\n",
    "                  row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(title_text=\"Scatter Plots of DataFrames 1 to 4\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=4, subplot_titles=(\n",
    "    \"DataFrame 1\",\n",
    "    \"DataFrame 2\",\n",
    "    \"DataFrame 3\",\n",
    "    \"DataFrame 4\"\n",
    "))\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    df_name = f'DataFrame {i+1}'\n",
    "    dcp_values = df_meta_feats_dict[df_name]['normalized_entropy']\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=df[\"X\"], y=df[\"Y\"], mode='markers',\n",
    "                             marker=dict(color=dcp_values,\n",
    "                                         colorscale='viridis',\n",
    "                                         cmin=0, cmax=1, \n",
    "                                         showscale=True if i == 3 else False, \n",
    "                                         colorbar=dict(title='normalized_entropy', x=1.02)),\n",
    "                             name=df_name),\n",
    "                  row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(title_text=\"Scatter Plots of DataFrames 1 to 4\", showlegend=False)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
